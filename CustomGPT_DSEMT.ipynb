{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1b926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.1-cp39-cp39-macosx_10_7_x86_64.whl (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.6/441.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.0-cp39-cp39-macosx_10_7_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "Successfully installed fsspec-2023.12.2 huggingface-hub-0.19.4 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.36.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569ebb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (2.1.1)\n",
      "Requirement already satisfied: networkx in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53bb14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_size = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_size)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68fe252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.23.7-cp39-none-macosx_10_9_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m946.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyMuPDFb==1.23.7\n",
      "  Downloading PyMuPDFb-1.23.7-py3-none-macosx_10_9_x86_64.whl (30.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.1/30.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.23.7 PyMuPDFb-1.23.7\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28a36405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def convert_pdf_to_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_number in range(doc.page_count):\n",
    "        page = doc[page_number]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_text = convert_pdf_to_text(\"Introduction to Machine Learning with Python ( PDFDrive.com )-min.pdf\")\n",
    "\n",
    "with open(\"dataset.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12c35b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='401' max='401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [401/401 06:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=401, training_loss=2.7350593243453867, metrics={'train_runtime': 397.5386, 'train_samples_per_second': 4.035, 'train_steps_per_second': 1.009, 'total_flos': 104778104832000.0, 'train_loss': 2.7350593243453867, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the GPT-2 model\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Read text from the pre-processed text file\n",
    "with open(\"dataset.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "# Preprocess the text (remove punctuation or stop words if needed)\n",
    "text_content = \"\".join(c for c in text_content if c not in ('!', '.', ',', ':', ';', '?'))\n",
    "\n",
    "# Tokenize the preprocessed text\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"dataset.txt\",\n",
    "    block_size=128  # Adjust as needed\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output/\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,  # Adjust as needed\n",
    "    per_device_train_batch_size=4,  # Adjust as needed\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29392e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (4.36.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (3.6.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (0.15.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (0.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: requests in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from transformers[torch]) (2.1.1)\n",
      "Collecting accelerate>=0.21.0\n",
      "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\n",
      "Requirement already satisfied: sympy in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.11.3)\n",
      "Requirement already satisfied: networkx in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers[torch]) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers[torch]) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.2.1)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install 'transformers[torch]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec9f474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (2.1.1)\n",
      "Requirement already satisfied: pyyaml in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: psutil in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: fsspec in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: filelock in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: networkx in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.11.3)\n",
      "Requirement already satisfied: sympy in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.10.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: requests in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2022.6.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anirudhajoshi/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e08b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is overfitting?\n",
      "Generated Responses:\n",
      "What is overfitting?\n",
      "\n",
      "Overfitting is a term used to refer to the fact that a garment is too tight or too loose, or that it is not fit properly. Overfitting can be caused by any number of factors, including the size of the garment, the length of time it has been in use, and the type of garment. It can also be due to a lack of proper fit, such as an undergarment, a tight fit on the back of a jacket or a loose fit in the waistband. The term \"overfitting\" is often used interchangeably with \"unfit\" or \"tight fit\". Overfit is defined as \"a garment that does not meet the requirements of its manufacturer's specifications and that is\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is underfitting?\n",
      "Generated Responses:\n",
      "What is underfitting?\n",
      "\n",
      "Underfitting is a term used to describe the way in which a person's appearance changes over time. For example, if you're wearing a dress, you might look like you've been wearing it for a long time, but you don't look as good as you did when you were younger. You may also look a little different from what you looked in the past, or you may look more like a different person than you do now.\n",
      ". Underfitting refers to the fact that your appearance is changing. This means that you are more likely to look good in a certain way, and you will look better in other ways. It is important to note that under-fitting does not mean you have to change your\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What are the advantages of using neural networks for image recognition?\n",
      "Generated Responses:\n",
      "What are the advantages of using neural networks for image recognition?\n",
      "\n",
      "Neural networks can be used for many different tasks. For example, it is possible to train a neural network to recognize a person's facial features, such as the shape of their nose, mouth, or eyes. In addition, the network can also be trained to perform tasks that are difficult for the human eye to process. These tasks are often difficult because they require a large amount of processing power, which is not available in the real world. Neural networks are also useful for other tasks where the user is unfamiliar with the task at hand (e.g., reading a book, playing video games, etc.). For instance, a user may not know how to read a sentence,\n",
      "==================================================\n",
      "Prompt: Apply the RBF kernel SVM to the Breast Cancer dataset\n",
      "Generated Responses:\n",
      "Apply the RBF kernel SVM to the Breast Cancer dataset.\n",
      "\n",
      "In this example, we will use the same data set as in the previous example. We will assume that we have a dataset of breast cancer patients with a mean age of 50 years and a median age at diagnosis of 20 years. In this case, the dataset will be used as the basis for our analysis. The first step in this analysis is to determine whether the data are representative of the general population. If so, then we can use a sample size of 1,000 to obtain a representative sample. This is done by dividing the sample by the number of patients who have been diagnosed with the disease and dividing it by 100. For the purposes of this study, this is\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# List of prompts\n",
    "prompts = [\n",
    "    \n",
    "    \"What is overfitting?\",\n",
    "    \"What is underfitting?\",\n",
    "    \"What are the advantages of using neural networks for image recognition?\",\n",
    "    \"Apply the RBF kernel SVM to the Breast Cancer dataset\"\n",
    "    \n",
    "]\n",
    "\n",
    "for user_prompt in prompts:\n",
    "    input_ids = tokenizer.encode(user_prompt, return_tensors=\"pt\")\n",
    "\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=150,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        early_stopping=True,\n",
    "        use_cache=True,\n",
    "        num_beams=5,\n",
    "    )\n",
    "\n",
    "    decoded_output = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output]\n",
    "\n",
    "    print(f\"Prompt: {user_prompt}\")\n",
    "    print(\"Generated Responses:\")\n",
    "    for response in decoded_output:\n",
    "        print(response)\n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758c392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
